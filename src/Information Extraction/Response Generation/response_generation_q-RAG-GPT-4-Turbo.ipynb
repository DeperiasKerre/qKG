{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36d291d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.31.0\n",
      "  Obtaining dependency information for transformers==4.31.0 from https://files.pythonhosted.org/packages/21/02/ae8e595f45b6c8edee07913892b3b41f5f5f273962ad98851dc6a564bbb9/transformers-4.31.0-py3-none-any.whl.metadata\n",
      "  Using cached transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers==4.31.0) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers==4.31.0) (0.25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers==4.31.0) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers==4.31.0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers==4.31.0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers==4.31.0) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers==4.31.0) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0)\n",
      "  Obtaining dependency information for tokenizers!=0.11.3,<0.14,>=0.11.1 from https://files.pythonhosted.org/packages/62/41/93d3135ec30f596a71490ce11a73572190fe80e85a2aea18f116a520cc41/tokenizers-0.13.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached tokenizers-0.13.3-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers==4.31.0) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers==4.31.0) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers==4.31.0) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers==4.31.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers==4.31.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers==4.31.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->transformers==4.31.0) (2023.7.22)\n",
      "Using cached transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "Using cached tokenizers-0.13.3-cp311-cp311-win_amd64.whl (3.5 MB)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.19.1\n",
      "    Uninstalling tokenizers-0.19.1:\n",
      "      Successfully uninstalled tokenizers-0.19.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.44.2\n",
      "    Uninstalling transformers-4.44.2:\n",
      "      Successfully uninstalled transformers-4.44.2\n",
      "Successfully installed tokenizers-0.13.3 transformers-4.31.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sentence-transformers 3.1.0 requires transformers<5.0.0,>=4.38.0, but you have transformers 4.31.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers==2.2.2\n",
      "  Using cached sentence_transformers-2.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (4.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (2.4.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (0.19.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (1.4.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (1.11.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (0.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (0.25.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers==2.2.2) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.4.3)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers==2.2.2) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers==2.2.2) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers==2.2.2) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers==2.2.2) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
      "Installing collected packages: sentence-transformers\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 3.1.0\n",
      "    Uninstalling sentence-transformers-3.1.0:\n",
      "      Successfully uninstalled sentence-transformers-3.1.0\n",
      "Successfully installed sentence-transformers-2.2.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: unknown command \"accelerate==0.21.0\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "'''\n",
    "!pip install transformers==4.31.0 \n",
    "!pip install sentence-transformers==2.2.2 \n",
    "!pip accelerate==0.21.0 \\\n",
    "!pip xformers==0.0.20 \\\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd599da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specific version to avoid error with vector store\n",
    "#!pip install chromadb==0.5.3\n",
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd76838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading training data for providing context to the model\n",
    "import pandas as pd\n",
    "train_data_df=pd.read_csv(\"C:/Users/USER/Documents/Projects/Instruction Dataset/LLM Training Data/train_data_split.csv\")\n",
    "## Convert the DataFrame to a format compatible with Hugging Face Datasets\n",
    "train_data_df['Instruction'] = train_data_df['Instruction']+ \". Input Text: \" + train_data_df['input_text'] + \"\\n\\nExtracted Properties:\\n\\n\"+ train_data_df['Output'].astype(str)\n",
    "train_dataset_dict = {\n",
    "    'instruction': train_data_df['Instruction'].tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d90b4483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify\n",
    "#train_dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "814acebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating context document from the list\n",
    "docs=train_dataset_dict['instruction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ca8e83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the embedding model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "import torch\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', cache_folder = '/data/base_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c965f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#do the embedding\n",
    "embeddings = embedding_model.encode(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3fb8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify the embeddings\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8ac9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indexing-run this only once\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection(name=\"q-rag_llama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c40433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#addding the train data\n",
    "collection.add(\n",
    "    embeddings = embeddings,\n",
    "    documents=docs,\n",
    "    ids= [str(i) for i in range(len(docs))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9fa28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieving\n",
    "def retrieve_vector_db(query, n_results=3):\n",
    "    results = collection.query(\n",
    "    query_embeddings = embedding_model.encode(query).tolist(),\n",
    "    n_results=n_results\n",
    "    )\n",
    "    return results['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db8d768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading test data for model evaluation\n",
    "import pandas as pd\n",
    "test_data_path=\"C:/Users/USER/Documents/Projects/Instruction Dataset/LLM Training Data/test_data_split.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78f589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing the test data to add the queries\n",
    "#defining the queries for the properties-we need to choose a query based on the input\n",
    "query_temperature=\"working temperature of the quantum cascade laser\"\n",
    "query_power= \"optical power of the quantum cascade laser\"\n",
    "query_frequency=\"lasing frequency of the quantum cascade laser\"\n",
    "query_hs=\"heterostructure of the quantum cascade laser\"\n",
    "query_design_type=\"design type of the quantum cascade laser\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5288d51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for the query keywords\n",
    "def check_text(row, column_name):\n",
    "    text = row[column_name].lower()\n",
    "    if \"working temperature\" in text:\n",
    "        return query_temperature\n",
    "    elif \"optical power\" in text:\n",
    "        return query_power\n",
    "    elif \"lasing frequency\" in text:\n",
    "        return query_frequency\n",
    "    elif \"query_hs\" in text:\n",
    "        return query_hs\n",
    "    else:\n",
    "        return query_design_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2339fdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing the data\n",
    "def process_csv(input_filepath, output_filepath, column_name):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(input_filepath)\n",
    "\n",
    "    # Check if the specified column exists\n",
    "    if column_name in df.columns:\n",
    "        # Apply the check_text function to the specified column and create a new column with the results\n",
    "        df['queries'] = df.apply(check_text, axis=1, args=(column_name,))\n",
    "    else:\n",
    "        print(f\"Column '{column_name}' does not exist in the CSV file.\")\n",
    "        return\n",
    "\n",
    "    # Save the modified DataFrame to a new CSV file\n",
    "    df.to_csv(output_filepath, index=False)\n",
    "    print(f\"Processed file saved as '{output_filepath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76562d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing the test data\n",
    "input_csv = test_data_path\n",
    "output_csv = 'processed_test_data.csv'\n",
    "column_to_check = 'Instruction'\n",
    "process_csv(input_csv, output_csv, column_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088aedfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the processed test data\n",
    "test_data_df=pd.read_csv('processed_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14d91e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting the data in some order and renaming the columns\n",
    "test_data_df=test_data_df[['queries', 'Instruction', 'input_text']]\n",
    "test_data_df.rename(columns={'Instruction': 'instructions', 'input_text': 'texts'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dc4319",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifying the ordered data\n",
    "#test_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f543ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to generate a list of prompts will be passed to the model.\n",
    "prompts=[]\n",
    "for a,b,c in zip(test_data_df['queries'],test_data_df['instructions'],test_data_df['texts']):\n",
    "    results=retrieve_vector_db(a)\n",
    "    context=results[0]\n",
    "    prompt = f'''\n",
    "[INST]\n",
    "Problem Definition: Extraction of quantum cascade laser properties from text entails extracting properties from a given text description. This should be done without providing any other additional information or explanations. The output format should correspond to the one in the example sentences. Example sentences containing an instruction, input text and the extracted properties are given below:\n",
    "\n",
    "Example Sentences: {context}\n",
    "\n",
    "Instruction: {b}\n",
    "\n",
    "Input Text: {c}\n",
    "\n",
    "[/INST]\n",
    "'''\n",
    "    prompts.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0829994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifying the list of prompts generated for each row in the dataset\n",
    "#display the prompt\n",
    "#prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e04e8114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n"
     ]
    }
   ],
   "source": [
    "#verify the length of the prompt list\n",
    "print(len(prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba69b821",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT\n",
    "import openai\n",
    "import os\n",
    "from IPython.display import Markdown\n",
    "api_key=\"OPEN_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60539a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set your API key securely\n",
    "openai.api_key = api_key\n",
    "\n",
    "def chatWithGPT4(user_text, print_output=False):\n",
    "    try:\n",
    "        # Creating text completions using the updated `ChatCompletion` class\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4-turbo\",  # Easily switch between \"gpt-3.5-turbo-0613\", \"gpt-4\", \"text-davinci-004\", or others\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                      {\"role\": \"user\", \"content\": user_text}],\n",
    "            max_tokens=3000\n",
    "        )\n",
    "        text_output = response['choices'][0]['message']['content'] if response['choices'] else \"No response generated.\"\n",
    "        if print_output:\n",
    "            print(text_output)\n",
    "        return text_output\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a79217e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n[INST]\\nProblem Definition: Extraction of quantum cascade laser properties from text entails extracting properties from a given text description. This should be done without providing any other additional information or explanations. The output format should correspond to the one in the example sentences. Example sentences containing an instruction, input text and the extracted properties are given below:\\n\\nExample Sentences: ['From the following sentence, please extract the lasing frequency of the Quantum Cascade Semiconductor laser device. Print none if the value does not exist in the input text. Input Text: We noticed a shift towards higher frequencies from the middle to the outskirts of the wafer in our observation of three GaAs/AlAs heterostructure-based lasers with target frequencies of 3.36 and 3.92 THz.\\\\t\\\\t\\\\n\\\\nExtracted Properties:\\\\n\\\\n3.36 and 3.92 THz.', 'From the following sentence, please extract the lasing frequency of the Quantum Cascade Semiconductor laser device. Print none if the value does not exist in the input text. Input Text: Using a bound-to-continuum active region and high-resistivity surface-plasmon waveguide design, we were able to achieve continuous-wave operation of 10.5 THz quantum cascade lasers emitting at 5.0 THz.\\\\n\\\\nExtracted Properties:\\\\n\\\\n10.5 THz, 5.0 THz', 'From the following sentence, please extract the lasing frequency of the Quantum Cascade Semiconductor laser device. Print none if the value does not exist in the input text. Input Text: By utilizing a bound-to-continuum active region and semi-insulating surface-plasmon waveguide design, we have successfully demonstrated the prolonged functioning of terahertz quantum cascade lasers emitting at 3.2 THz in continuous-wave mode.\\\\t\\\\n\\\\nExtracted Properties:\\\\n\\\\n3.2 THz']\\n\\nInstruction: From the following sentence, please extract the lasing frequency of the Quantum Cascade Semiconductor laser device. Print none if the value does not exist in the input text\\n\\nInput Text: A sharp spike in spectral emission was detected at exactly 3.3 THz.\\n\\n[/INST]\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking a sample prompt at a particular index in the list of prompts\n",
    "prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e386d209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the model responses in a list\n",
    "responses=[]\n",
    "for prompt in prompts:\n",
    "    result=chatWithGPT4(prompt)\n",
    "    responses.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2534432e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Extracted Properties:\\n\\n3.3 THz',\n",
       " 'Extracted Properties:\\n\\n10 mW',\n",
       " 'Extracted Properties:\\n\\n2.07 THz, 2.02 THz',\n",
       " 'Extracted Properties:\\n\\n190 K, 125 K',\n",
       " 'Extracted Properties:\\n\\n107 K, 91 K',\n",
       " 'Extracted Properties:\\n\\nGaAs/Al0.23Ga0.77As',\n",
       " 'Extracted Properties:\\n\\nIn0.6Ga0.4As/InAs',\n",
       " 'Extracted Properties:\\n\\n3.0 THz',\n",
       " 'Extracted Properties:\\n\\n185 K',\n",
       " 'Extracted Properties:\\n\\n325 K',\n",
       " 'Extracted Properties:\\n\\nnone',\n",
       " 'Extracted Properties:\\n\\n195 K',\n",
       " 'Extracted Properties:\\n\\n24 mW',\n",
       " 'Extracted Properties:\\n\\nnone',\n",
       " 'Extracted Properties:\\n\\n150 K, 110 K',\n",
       " 'Extracted Properties:\\n\\nnone',\n",
       " 'Extracted Properties:\\n\\n113 K, 89 K',\n",
       " 'Extracted Properties:\\n\\n70K',\n",
       " 'Extracted Properties:\\n\\nnone',\n",
       " 'Extracted Properties:\\n\\nnone',\n",
       " 'Extracted Properties:\\n\\n182 K',\n",
       " 'Extracted Properties:\\n\\nnone',\n",
       " 'Extracted Properties:\\n\\nGaAs/Al0.15Ga0.85As',\n",
       " 'Extracted Properties:\\n\\nnone',\n",
       " 'Extracted Properties:\\n\\nLO-phonon-based depopulation',\n",
       " 'Extracted Properties:\\n\\n3.5 THz',\n",
       " 'Extracted Properties:\\n\\n115 K, 98 K',\n",
       " 'Extracted Properties:\\n\\n13.5 THz',\n",
       " 'Extracted Properties:\\n\\n12.4 THz',\n",
       " 'Extracted Properties:\\n\\n9.5 THz',\n",
       " 'Extracted Properties:\\n\\nGaAs/Al0.15Ga0.85As',\n",
       " 'Extracted Properties:\\n\\nscattering-assisted injection, resonant-phonon depopulation',\n",
       " 'Extracted Properties:\\n\\n1.88 and 2.42 THz',\n",
       " 'Extracted Properties:\\n\\nnone',\n",
       " 'Extracted Properties:\\n\\n18 mW',\n",
       " 'Extracted Properties:\\n\\n6 THz',\n",
       " 'Extracted Properties:\\n\\n10 mW',\n",
       " 'Extracted Properties:\\n\\nGaAs/AlGaAs',\n",
       " 'Extracted Properties:\\n\\n5.2 THz',\n",
       " 'Extracted Properties:\\n\\n15 mW',\n",
       " 'Extracted Properties:\\n\\n8.2 THz',\n",
       " 'Extracted Properties:\\n\\n10 milliwatts',\n",
       " 'Extracted Properties:\\n\\nbound-to-continuum',\n",
       " 'Extracted Properties:\\n\\n2.12 THz, 2.06 THz',\n",
       " 'Extracted Properties:\\n\\n260 K',\n",
       " 'Extracted Properties:\\n\\nbound-to-continuum',\n",
       " 'Extracted Properties:\\n\\nnone',\n",
       " 'Extracted Properties:\\n\\n119 K',\n",
       " 'Extracted Properties:\\n\\n225 K',\n",
       " 'Extracted Properties:\\n\\nGaAs/Al0.15Ga0.85As',\n",
       " 'Extracted Properties:\\n\\nGaN/In0.3Ga0.7As',\n",
       " 'Extracted Properties:\\n\\nnone',\n",
       " 'Extracted Properties:\\n\\n5.6 W',\n",
       " 'Extracted Properties:\\n\\nscattering-assisted injection and resonant-phonon depopulation',\n",
       " 'Extracted Properties:\\n\\n25.1 W',\n",
       " 'Extracted Properties:\\n\\n3.63 THz',\n",
       " 'Extracted Properties:\\n\\nGaAs/Al0.12Ga0.88As',\n",
       " 'Extracted Properties:\\n\\nbound-to-continuum',\n",
       " 'Extracted Properties:\\n\\nInGaN/AlGaN',\n",
       " 'Extracted Properties:\\n\\nnone',\n",
       " 'Extracted Properties:\\n\\n0.7 mW',\n",
       " 'Extracted Properties:\\n\\n144 K',\n",
       " 'Extracted Properties:\\n\\n168 K, 121 K',\n",
       " 'Extracted Properties:\\n\\n95K',\n",
       " 'Extracted Properties:\\n\\nresonant LO phonon scheme',\n",
       " 'Extracted Properties:\\n\\n40mW',\n",
       " 'Extracted Properties:\\n\\n8 mW',\n",
       " 'Extracted Properties:\\n\\n0.8 mW',\n",
       " 'Extracted Properties:\\n\\n3 to 4.7 THz',\n",
       " 'Extracted Properties:\\n\\n155 K',\n",
       " 'Extracted Properties:\\n\\n0.9 mW',\n",
       " 'Extracted Properties:\\n\\n110 K',\n",
       " 'Extracted Properties:\\n\\n235 K',\n",
       " 'Extracted Properties:\\n\\n1.2 THz',\n",
       " 'Extracted Properties:\\n\\n33 mW',\n",
       " 'Extracted Properties:\\n\\n119K',\n",
       " 'Extracted Properties:\\n\\n0.6 mW',\n",
       " 'Extracted Properties:\\n\\n90mW',\n",
       " 'Extracted Properties:\\n\\n175 K',\n",
       " 'Extracted Properties:\\n\\nnone',\n",
       " 'Extracted Properties:\\n\\nbound-to-continuum',\n",
       " 'Extracted Properties:\\n\\n2.62 THz',\n",
       " 'Extracted Properties:\\n\\n4.5 mW',\n",
       " 'Extracted Properties:\\n\\n3 THz',\n",
       " 'Extracted Properties:\\n\\nnone',\n",
       " 'Extracted Properties:\\n\\n165 K',\n",
       " 'Extracted Properties:\\n\\n5 THz',\n",
       " 'Extracted Properties:\\n\\n85 K, 20 K',\n",
       " 'Extracted Properties:\\n\\n27 mW',\n",
       " 'Extracted Properties:\\n\\nnone',\n",
       " 'Extracted Properties:\\n\\n9 THz',\n",
       " 'Extracted Properties:\\n\\n1.8 THz',\n",
       " 'Extracted Properties:\\n\\nnone',\n",
       " 'Extracted Properties:\\n\\n2 mW',\n",
       " 'Extracted Properties:\\n\\n180 K, 110 K',\n",
       " 'Extracted Properties:\\n\\n7 THz',\n",
       " 'Extracted Properties:\\n\\n170 K',\n",
       " 'Extracted Properties:\\n\\n2.5 mW',\n",
       " 'Extracted Properties:\\n\\n0.5 mW',\n",
       " 'Extracted Properties:\\n\\n220 K, 135 K',\n",
       " 'Extracted Properties:\\n\\nbound-to-continuum',\n",
       " 'Extracted Properties:\\n\\n35 mW',\n",
       " 'Extracted Properties:\\n\\nGaAs/Al0.15Ga0.85As',\n",
       " 'Extracted Properties:\\n\\nnone',\n",
       " 'Extracted Properties:\\n\\n250 mW',\n",
       " 'Extracted Properties:\\n\\nIn0.53Ga0.47As/GaAs0.51Sb0.49',\n",
       " 'Extracted Properties:\\n\\nnone',\n",
       " 'Extracted Properties:\\n\\n178 K',\n",
       " 'Extracted Properties:\\n\\n5.37 THz',\n",
       " 'Extracted Properties:\\n\\n0.5 mW',\n",
       " 'Extracted Properties:\\n\\n217 K',\n",
       " 'Extracted Properties:\\n\\n220 K',\n",
       " 'Extracted Properties:\\n\\n5.3 THz',\n",
       " 'Extracted Properties:\\n\\nbound-to-continuum',\n",
       " 'Extracted Properties:\\n\\nGaAs/Al0.25Ga0.75As',\n",
       " 'Extracted Properties:\\n\\nInAs/InP',\n",
       " 'Extracted Properties:\\n\\n0.23 W',\n",
       " 'Extracted Properties:\\n\\n100K',\n",
       " 'Extracted Properties:\\n\\nbound-to-continuum',\n",
       " 'Extracted Properties:\\n\\nresonant LO phonon',\n",
       " 'Extracted Properties:\\n\\n0.23 W',\n",
       " 'Extracted Properties:\\n\\n300 K',\n",
       " 'Extracted Properties:\\n\\n3.36 and 3.92 THz',\n",
       " 'Extracted Properties:\\n\\nmultilayer',\n",
       " 'Extracted Properties:\\n\\n7.3 THz',\n",
       " 'Extracted Properties:\\n\\n8.9 THz',\n",
       " 'Extracted Properties:\\n\\n180 K',\n",
       " 'Extracted Properties:\\n\\n164 K, 117 K',\n",
       " 'Extracted Properties:\\n\\n2 THz',\n",
       " 'Extracted Properties:\\n\\n3.9 THz']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dispalying the responses\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebefc214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List saved to qcl-RAG-GPT4-Turbo-responses.csv\n"
     ]
    }
   ],
   "source": [
    "#writing the model responses to a csv file\n",
    "import csv\n",
    "\n",
    "# Name of the csv file to save the list\n",
    "file_name = \"qcl-RAG-GPT4-Turbo-responses.csv\"\n",
    "\n",
    "# Writing the list to a csv file with one column\n",
    "with open(file_name, \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    for item in responses:\n",
    "        writer.writerow([item])\n",
    "\n",
    "print(\"List saved to\", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b854df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
