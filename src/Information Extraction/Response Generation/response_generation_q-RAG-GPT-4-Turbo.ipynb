{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36d291d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install transformers==4.31.0 \\n!pip install sentence-transformers==2.2.2 \\n!pip accelerate==0.21.0 !pip xformers==0.0.20 '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#libraries\n",
    "'''\n",
    "!pip install transformers==4.31.0 \n",
    "!pip install sentence-transformers==2.2.2 \n",
    "!pip accelerate==0.21.0 \\\n",
    "!pip xformers==0.0.20 \\\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bccad01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2025-11-12 14:45:25 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# execution time tracking\n",
    "#!pip install ipython-autotime\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd599da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2025-11-12 14:45:44 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#specific version to avoid error with vector store\n",
    "#!pip install chromadb==0.5.3\n",
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd76838d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.73 s (started: 2025-11-12 14:45:44 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#loading training data for providing context to the model\n",
    "import pandas as pd\n",
    "train_data_df=pd.read_csv(\"C:/Users/USER/Documents/Projects/Instruction Dataset/LLM Training Data/new data/train_data_split.csv\")\n",
    "## Convert the DataFrame to a format compatible with Hugging Face Datasets\n",
    "train_data_df['Instruction'] = train_data_df['Instruction']+ \". Input Text: \" + train_data_df['input_text'] + \"\\n\\nExtracted Properties:\\n\\n\"+ train_data_df['Output'].astype(str)\n",
    "train_dataset_dict = {\n",
    "    'instruction': train_data_df['Instruction'].tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d90b4483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2025-11-12 14:45:46 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#verify\n",
    "#train_dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "814acebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2025-11-12 14:45:48 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#creating context document from the list\n",
    "docs=train_dataset_dict['instruction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ca8e83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 23.9 s (started: 2025-11-12 14:45:49 +01:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#initializing the embedding model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "import torch\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', cache_folder = '/data/base_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4c965f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3min 56s (started: 2025-11-12 14:46:13 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#do the embedding\n",
    "embeddings = embedding_model.encode(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf3fb8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040, 768)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2025-11-12 14:50:09 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#verify the embeddings\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd8ac9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 672 ms (started: 2025-11-12 14:50:09 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#indexing-run this only once\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection(name=\"q-rag_GPT4-Turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76c40433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.88 s (started: 2025-11-12 14:50:10 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#addding the train data\n",
    "collection.add(\n",
    "    embeddings = embeddings,\n",
    "    documents=docs,\n",
    "    ids= [str(i) for i in range(len(docs))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a9fa28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2025-11-12 14:50:13 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#retrieving\n",
    "def retrieve_vector_db(query, n_results=3):\n",
    "    results = collection.query(\n",
    "    query_embeddings = embedding_model.encode(query).tolist(),\n",
    "    n_results=n_results\n",
    "    )\n",
    "    return results['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1db8d768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2025-11-12 14:50:13 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#loading test data for model evaluation\n",
    "import pandas as pd\n",
    "test_data_path=\"C:/Users/USER/Documents/Projects/Instruction Dataset/LLM Training Data/new data/test_data_split.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d78f589f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2025-11-12 14:50:13 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#processing the test data to add the queries\n",
    "#defining the queries for the properties-we need to choose a query based on the input\n",
    "query_temperature=\"working temperature of the quantum cascade laser\"\n",
    "query_power= \"optical power of the quantum cascade laser\"\n",
    "query_frequency=\"lasing frequency of the quantum cascade laser\"\n",
    "query_hs=\"heterostructure of the quantum cascade laser\"\n",
    "query_design_type=\"design type of the quantum cascade laser\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5288d51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2025-11-12 14:50:13 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#checking for the query keywords\n",
    "def check_text(row, column_name):\n",
    "    text = row[column_name].lower()\n",
    "    if \"working temperature\" in text:\n",
    "        return query_temperature\n",
    "    elif \"optical power\" in text:\n",
    "        return query_power\n",
    "    elif \"lasing frequency\" in text:\n",
    "        return query_frequency\n",
    "    elif \"query_hs\" in text:\n",
    "        return query_hs\n",
    "    else:\n",
    "        return query_design_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2339fdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2025-11-12 14:50:13 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#processing the data\n",
    "def process_csv(input_filepath, output_filepath, column_name):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(input_filepath)\n",
    "\n",
    "    # Check if the specified column exists\n",
    "    if column_name in df.columns:\n",
    "        # Apply the check_text function to the specified column and create a new column with the results\n",
    "        df['queries'] = df.apply(check_text, axis=1, args=(column_name,))\n",
    "    else:\n",
    "        print(f\"Column '{column_name}' does not exist in the CSV file.\")\n",
    "        return\n",
    "\n",
    "    # Save the modified DataFrame to a new CSV file\n",
    "    df.to_csv(output_filepath, index=False)\n",
    "    print(f\"Processed file saved as '{output_filepath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f76562d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved as 'processed_test_data.csv'.\n",
      "time: 32 ms (started: 2025-11-12 14:50:13 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#processing the test data\n",
    "input_csv = test_data_path\n",
    "output_csv = 'processed_test_data.csv'\n",
    "column_to_check = 'Instruction'\n",
    "process_csv(input_csv, output_csv, column_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "088aedfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 32 ms (started: 2025-11-12 14:50:13 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#loading the processed test data\n",
    "test_data_df=pd.read_csv('processed_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c14d91e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2025-11-12 14:50:13 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#putting the data in some order and renaming the columns\n",
    "test_data_df=test_data_df[['queries', 'Instruction', 'input_text']]\n",
    "test_data_df.rename(columns={'Instruction': 'instructions', 'input_text': 'texts'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85dc4319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2025-11-12 14:50:13 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#verifying the ordered data\n",
    "#test_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f543ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.4 s (started: 2025-11-12 14:50:13 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#we need to generate a list of prompts will be passed to the model.\n",
    "prompts=[]\n",
    "for a,b,c in zip(test_data_df['queries'],test_data_df['instructions'],test_data_df['texts']):\n",
    "    results=retrieve_vector_db(a)\n",
    "    context=results[0]\n",
    "    prompt = f'''\n",
    "[INST]\n",
    "Problem Definition: Extraction of quantum cascade laser properties from text entails extracting properties from a given text description. This should be done without providing any other additional information or explanations. The output format should correspond to the one in the example sentences. Example sentences containing an instruction, input text and the extracted properties are given below:\n",
    "\n",
    "Example Sentences: {context}\n",
    "\n",
    "Instruction: {b}\n",
    "\n",
    "Input Text: {c}\n",
    "\n",
    "[/INST]\n",
    "'''\n",
    "    prompts.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0829994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2025-11-12 14:50:25 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#verifying the list of prompts generated for each row in the dataset\n",
    "#display the prompt\n",
    "#prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e04e8114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "time: 16 ms (started: 2025-11-12 14:50:25 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#verify the length of the prompt list\n",
    "print(len(prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba69b821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 375 ms (started: 2025-11-12 14:50:25 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#GPT\n",
    "import openai\n",
    "import os\n",
    "from IPython.display import Markdown\n",
    "api_key=\"OPEN_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60539a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2025-11-12 14:50:26 +01:00)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# Set your API key securely\n",
    "openai.api_key = api_key\n",
    "\n",
    "def chatWithGPT4(user_text, print_output=False):\n",
    "    try:\n",
    "        # Creating text completions using the updated `ChatCompletion` class\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4-turbo\",  # Easily switch between \"gpt-3.5-turbo-0613\", \"gpt-4\", \"text-davinci-004\", or others\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                      {\"role\": \"user\", \"content\": user_text}],\n",
    "            max_tokens=3000\n",
    "        )\n",
    "        text_output = response['choices'][0]['message']['content'] if response['choices'] else \"No response generated.\"\n",
    "        if print_output:\n",
    "            print(text_output)\n",
    "        return text_output\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a79217e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2025-11-12 14:50:26 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#checking a sample prompt at a particular index in the list of prompts\n",
    "#prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e386d209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 29s (started: 2025-11-12 14:50:26 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#getting the model responses in a list\n",
    "responses=[]\n",
    "for prompt in prompts:\n",
    "    result=chatWithGPT4(prompt)\n",
    "    responses.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2534432e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Extracted Properties:\\n\\n3.3 THz',\n",
       " 'Extracted Properties:\\n\\n10 mW',\n",
       " 'Extracted Properties:\\n\\n2.07 THz, 2.02 THz',\n",
       " 'Extracted Properties:\\n\\n190 K, 125 K',\n",
       " 'Extracted Properties:\\n\\n107 K, 91 K',\n",
       " 'Extracted Properties:\\n\\nGaAs/Al0.23Ga0.77As',\n",
       " 'Extracted Properties:\\n\\nIn0.6Ga0.4As/InAs',\n",
       " 'Extracted Properties:\\n\\n3.0 THz',\n",
       " 'Extracted Properties:\\n\\n185 K',\n",
       " 'Extracted Properties:\\n\\n325 K',\n",
       " 'Extracted Properties:\\n\\nresonant-phonon',\n",
       " 'Extracted Properties:\\n\\n195 K',\n",
       " 'Extracted Properties:\\n\\n24 mW',\n",
       " 'Extracted Properties:\\n\\nLO-phonon',\n",
       " 'Extracted Properties:\\n\\n150 K, 110 K',\n",
       " 'Extracted Properties:\\n\\nLO-phonon',\n",
       " 'Extracted Properties:\\n\\n113 K, 89 K',\n",
       " 'Extracted Properties:\\n\\n70K',\n",
       " 'Extracted Properties:\\n\\nLO phonon',\n",
       " 'Extracted Properties:\\n\\nresonant-phonon',\n",
       " 'Extracted Properties:\\n\\n182 K',\n",
       " 'Extracted Properties:\\n\\nnone',\n",
       " 'Extracted Properties:\\n\\nGaAs/Al0.15Ga0.85As',\n",
       " 'Extracted Properties:\\n\\nLO phonon',\n",
       " 'Extracted Properties:\\n\\nLO-phonon-based depopulation',\n",
       " 'Extracted Properties:\\n\\n3.5 THz',\n",
       " 'Extracted Properties:\\n\\n115 K, 98 K',\n",
       " 'Extracted Properties:\\n\\n13.5 THz',\n",
       " 'Extracted Properties:\\n\\n12.4 THz',\n",
       " 'Extracted Properties:\\n\\n9.5 THz',\n",
       " 'Extracted Properties:\\n\\nGaAs/Al0.15Ga0.85As',\n",
       " 'Extracted Properties:\\n\\nscattering-assisted injection, resonant-phonon',\n",
       " 'Extracted Properties:\\n\\n1.88 THz, 2.42 THz',\n",
       " 'Extracted Properties:\\n\\nLO phonon',\n",
       " 'Extracted Properties:\\n\\n18mW',\n",
       " 'Extracted Properties:\\n\\n6 THz',\n",
       " 'Extracted Properties:\\n\\n~10 mW',\n",
       " 'Extracted Properties:\\n\\nGaAs/AlGaAs',\n",
       " 'Extracted Properties:\\n\\n5.2 THz',\n",
       " 'Extracted Properties:\\n\\n~15 mW',\n",
       " 'Extracted Properties:\\n\\n8.2 THz',\n",
       " 'Extracted Properties:\\n\\n10 milliwatts',\n",
       " 'Extracted Properties:\\n\\nbound-to-continuum',\n",
       " 'Extracted Properties:\\n\\n2.12 THz, 2.06 THz',\n",
       " 'Extracted Properties:\\n\\n260 K',\n",
       " 'Extracted Properties:\\n\\nbound-to-continuum',\n",
       " 'Extracted Properties:\\n\\nresonant-phonon',\n",
       " 'Extracted Properties:\\n\\n119 K',\n",
       " 'Extracted Properties:\\n\\n225 K',\n",
       " 'Extracted Properties:\\n\\nGaAs/Al0.15Ga0.85As',\n",
       " 'Extracted Properties:\\n\\nGaN/In0.3Ga0.7As',\n",
       " 'Extracted Properties:\\n\\nresonant-phonon',\n",
       " 'Extracted Properties:\\n\\n5.6 W',\n",
       " 'Extracted Properties:\\n\\n9.2 THz',\n",
       " 'Extracted Properties:\\n\\n25.1 W',\n",
       " 'Extracted Properties:\\n\\n3.63 THz',\n",
       " 'Extracted Properties:\\n\\nGaAs/Al0.12Ga0.88As',\n",
       " 'Extracted Properties:\\n\\nbound-to-continuum',\n",
       " 'Extracted Properties:\\n\\nInGaN/AlGaN',\n",
       " 'Extracted Properties:\\n\\nLO-phonon',\n",
       " 'Extracted Properties:\\n\\n0.7 mW',\n",
       " 'Extracted Properties:\\n\\n144 K',\n",
       " 'Extracted Properties:\\n\\n168 K, 121 K',\n",
       " 'Extracted Properties:\\n\\n95K',\n",
       " 'Extracted Properties:\\n\\nLO phonon',\n",
       " 'Extracted Properties:\\n\\n40mW',\n",
       " 'Extracted Properties:\\n\\n8mW',\n",
       " 'Extracted Properties:\\n\\n0.8 mW',\n",
       " 'Extracted Properties:\\n\\n3 to 4.7 THz',\n",
       " 'Extracted Properties:\\n\\n155 K',\n",
       " 'Extracted Properties:\\n\\n0.9 mW',\n",
       " 'Extracted Properties:\\n\\n110 K',\n",
       " 'Extracted Properties:\\n\\n235 K',\n",
       " 'Extracted Properties:\\n\\n1.2 THz',\n",
       " 'Extracted Properties:\\n\\n33 mW',\n",
       " 'Extracted Properties:\\n\\n119K',\n",
       " 'Extracted Properties:\\n\\n0.6 mW',\n",
       " 'Extracted Properties:\\n\\n90mW',\n",
       " 'Extracted Properties:\\n\\n175 K',\n",
       " 'Extracted Properties:\\n\\nresonant-phonon',\n",
       " 'Extracted Properties:\\n\\nbound-to-continuum',\n",
       " 'Extracted Properties:\\n\\n2.62 THz',\n",
       " 'Extracted Properties:\\n\\n4.5 mW',\n",
       " 'Extracted Properties:\\n\\n3 THz',\n",
       " 'Extracted Properties:\\n\\nLO phonon',\n",
       " 'Extracted Properties:\\n\\n165 K',\n",
       " 'Extracted Properties:\\n\\n5 THz',\n",
       " 'Extracted Properties:\\n\\n85 K',\n",
       " 'Extracted Properties:\\n\\n~27 mW',\n",
       " 'Extracted Properties:\\n\\nnone',\n",
       " 'Extracted Properties:\\n\\n9 THz',\n",
       " 'Extracted Properties:\\n\\n1.8 THz',\n",
       " 'Extracted Properties:\\n\\nresonant-phonon',\n",
       " 'Extracted Properties:\\n\\n2 mW',\n",
       " 'Extracted Properties:\\n\\n180 K, 110 K',\n",
       " 'Extracted Properties:\\n\\n7 THz',\n",
       " 'Extracted Properties:\\n\\n170 K',\n",
       " 'Extracted Properties:\\n\\n2.5 mW',\n",
       " 'Extracted Properties:\\n\\n0.5 mW',\n",
       " 'Extracted Properties:\\n\\n220 K, 135 K',\n",
       " 'Extracted Properties:\\n\\nbound-to-continuum',\n",
       " 'Extracted Properties:\\n\\n35 mW',\n",
       " 'Extracted Properties:\\n\\nGaAs/Al0.15Ga0.85As',\n",
       " 'Extracted Properties:\\n\\nresonant-phonon',\n",
       " 'Extracted Properties:\\n\\n250mW',\n",
       " 'Extracted Properties:\\n\\nIn0.53Ga0.47As/GaAs0.51Sb0.49',\n",
       " 'Extracted Properties:\\n\\nnone',\n",
       " 'Extracted Properties:\\n\\n178 K',\n",
       " 'Extracted Properties:\\n\\n5.37 THz',\n",
       " 'Extracted Properties:\\n\\n0.5 mW',\n",
       " 'Extracted Properties:\\n\\n217 K',\n",
       " 'Extracted Properties:\\n\\n220 K',\n",
       " 'Extracted Properties:\\n\\n5.3 THz',\n",
       " 'Extracted Properties:\\n\\nbound-to-continuum',\n",
       " 'Extracted Properties:\\n\\nGaAs/Al0.25Ga0.75As',\n",
       " 'Extracted Properties:\\n\\nInAs/InP',\n",
       " 'Extracted Properties:\\n\\n0.23 W',\n",
       " 'Extracted Properties:\\n\\n100K',\n",
       " 'Extracted Properties:\\n\\nbound-to-continuum',\n",
       " 'Extracted Properties:\\n\\nLO phonon',\n",
       " 'Extracted Properties:\\n\\n0.23 W',\n",
       " 'Extracted Properties:\\n\\n300 K',\n",
       " 'Extracted Properties:\\n\\n3.36 and 3.92 THz',\n",
       " 'Extracted Properties:\\n\\nmultilayer (MH)',\n",
       " 'Extracted Properties:\\n\\n7.3 THz',\n",
       " 'Extracted Properties:\\n\\n8.9 THz',\n",
       " 'Extracted Properties:\\n\\n180 K',\n",
       " 'Extracted Properties:\\n\\n169 K, 124 K',\n",
       " 'Extracted Properties:\\n\\n2 THz',\n",
       " 'Extracted Properties:\\n\\n3.9 THz']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2025-11-12 14:52:55 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#dispalying the responses\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebefc214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List saved to qcl-RAG-GPT4-Turbo-responses.csv\n",
      "time: 0 ns (started: 2025-11-12 14:52:55 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#writing the model responses to a csv file\n",
    "import csv\n",
    "\n",
    "# Name of the csv file to save the list\n",
    "file_name = \"qcl-RAG-GPT4-Turbo-responses.csv\"\n",
    "\n",
    "# Writing the list to a csv file with one column\n",
    "with open(file_name, \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    for item in responses:\n",
    "        writer.writerow([item])\n",
    "\n",
    "print(\"List saved to\", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b854df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
