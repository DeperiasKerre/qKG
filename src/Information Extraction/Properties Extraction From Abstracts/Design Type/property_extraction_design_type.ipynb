{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c517bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install transformers==4.31.0 \\n!pip install sentence-transformers==2.2.2 \\n!pip accelerate==0.21.0 !pip xformers==0.0.20 '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#libraries\n",
    "'''\n",
    "!pip install transformers==4.31.0 \n",
    "!pip install sentence-transformers==2.2.2 \n",
    "!pip accelerate==0.21.0 \\\n",
    "!pip xformers==0.0.20 \\\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a09b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specific version to avoid error with vector store\n",
    "#!pip install chromadb==0.5.3\n",
    "#!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a211e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update transformers\n",
    "#!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bec40989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading training data for providing context to the model\n",
    "import pandas as pd\n",
    "train_data_df=pd.read_csv(\"C:/Users/USER/Documents/Projects/Instruction Dataset/LLM Training Data/train_data_split.csv\")\n",
    "## Convert the DataFrame to a format compatible with Hugging Face Datasets\n",
    "train_data_df['Instruction'] = train_data_df['Instruction']+ \". Input Text: \" + train_data_df['input_text'] + \"\\n\\nExtracted Properties:\\n\\n\"+ train_data_df['Output'].astype(str)\n",
    "train_dataset_dict = {\n",
    "    'instruction': train_data_df['Instruction'].tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45b677f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating context document from the list\n",
    "docs=train_dataset_dict['instruction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "672d3a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#initializing the embedding model\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "import torch\n",
    "embedding_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', cache_folder = '/data/base_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dc0c2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040, 768)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#do the embedding\n",
    "embeddings = embedding_model.encode(docs)\n",
    "#verify the embeddings\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81c3552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indexing-run this only once\n",
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.create_collection(name=\"q-rag_llama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d614d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#addding the train data\n",
    "collection.add(\n",
    "    embeddings = embeddings,\n",
    "    documents=docs,\n",
    "    ids= [str(i) for i in range(len(docs))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffa0e9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function for retrieval  \n",
    "#retrieving\n",
    "def retrieve_vector_db(query, n_results=3):\n",
    "    results = collection.query(\n",
    "    query_embeddings = embedding_model.encode(query).tolist(),\n",
    "    n_results=n_results\n",
    "    )\n",
    "    return results['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c80ec37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the abstracts\n",
    "import pandas as pd\n",
    "abstracts_path=\"C:/Users/USER/Documents/Projects/KG/Data/abstracts/abstracts.csv\"\n",
    "abstracts_df=pd.read_csv(abstracts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13003f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Abstracts: 42\n"
     ]
    }
   ],
   "source": [
    "#pass the abstracts to a list\n",
    "abstracts=abstracts_df['Abstract'].tolist()\n",
    "#number of abstracts\n",
    "print(\"Number of Abstracts:\",len(abstracts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12a5e184",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print list of abstracts\n",
    "#abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29f89f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up the query\n",
    "query=\"From the following sentence, please extract the design type of the Quantum Cascade Semiconductor laser device. Print none if the value does not exist in the input text:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42363e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating a list of prompt for ecah abstract for power extraction\n",
    "prompts=[]\n",
    "for abstract in abstracts:\n",
    "    results=retrieve_vector_db(query)\n",
    "    context=results[0]\n",
    "    prompt = f'''\n",
    "[INST]\n",
    "Problem Definition: Extraction of quantum cascade laser properties from text entails extracting properties from a given text description. This should be done without providing any other additional information or explanations.\n",
    "\n",
    "Example Sentences containing instructions for extracting properties, the input text and the corresponding extracted properties: {context}\n",
    "\n",
    "Instruction: {query}\n",
    "\n",
    "Input Text: {abstract}\n",
    "\n",
    "[/INST]\n",
    "'''\n",
    "    prompts.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8943f095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of prompts: 42\n"
     ]
    }
   ],
   "source": [
    "print(\"number of prompts:\", len(prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e86c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifying the list of prompts generated for each row in the dataset\n",
    "#display the prompt\n",
    "#prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7367a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT\n",
    "import openai\n",
    "import os\n",
    "from IPython.display import Markdown\n",
    "api_key=\"OPENAI_API_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8f4b81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set your API key securely\n",
    "openai.api_key = api_key\n",
    "\n",
    "def chatWithGPT4(user_text, print_output=False):\n",
    "    try:\n",
    "        # Creating text completions using the updated `ChatCompletion` class\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4-turbo\",  # Easily switch between \"gpt-3.5-turbo-0613\", \"gpt-4\", \"text-davinci-004\", or others\n",
    "            messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                      {\"role\": \"user\", \"content\": user_text}],\n",
    "            max_tokens=3000\n",
    "        )\n",
    "        text_output = response['choices'][0]['message']['content'] if response['choices'] else \"No response generated.\"\n",
    "        if print_output:\n",
    "            print(text_output)\n",
    "        return text_output\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "809604c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the model responses in a list\n",
    "design_type_properties=[]\n",
    "for prompt in prompts:\n",
    "    result=chatWithGPT4(prompt)\n",
    "    design_type_properties.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fafbf4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['none',\n",
       " 'scattering-assisted injection and resonant-phonon depopulation',\n",
       " 'longitudinal-optical (LO) phonon',\n",
       " 'resonant-phonon, diagonal',\n",
       " 'indirectly pumped',\n",
       " 'consecutive phonon-photon-phonon',\n",
       " 'distributed feedback',\n",
       " 'Extracted Properties:\\n\\nbound-to-continuum, semi-insulating surface-plasmon waveguide design',\n",
       " 'none',\n",
       " 'multilayer heterostructure',\n",
       " 'dual lasing channel',\n",
       " 'band design',\n",
       " 'none',\n",
       " 'three-well phonon depletion',\n",
       " 'semi-insulating surface plasmon waveguides',\n",
       " 'semiinsulating surface-plasmon waveguide',\n",
       " 'none',\n",
       " '3-well resonant phonon depletion',\n",
       " 'four-quantum-well',\n",
       " 'bound-to-continuum',\n",
       " 'resonant-phonon',\n",
       " 'none',\n",
       " 'resonant-phonon',\n",
       " 'planarized double metal',\n",
       " 'none',\n",
       " 'electrically-switchable dual-wavelength',\n",
       " 'none',\n",
       " 'longitudinal-optical phonon',\n",
       " 'lattice-matched quaternary AlInGaAs',\n",
       " 'three-well phonon depopulation',\n",
       " 'bound-to-continuum',\n",
       " 'Extracted Properties:\\n\\nresonant-phonon',\n",
       " 'bound-to-continuum',\n",
       " 'two longitudinal-optical phonon scattering events',\n",
       " 'double-phonon resonant depopulation',\n",
       " 'resonant-phonon',\n",
       " 'three-well active modules',\n",
       " 'dual-wavelength mid-infrared',\n",
       " 'none',\n",
       " 'vertical-external-cavity',\n",
       " 'two-phonon-resonance',\n",
       " 'two-well injector direct-phonon']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#viweing the extracted properties\n",
    "design_type_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "70cca96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List saved to design_type_properties.csv\n"
     ]
    }
   ],
   "source": [
    "#save the extracted properties in a csv file\n",
    "import csv\n",
    "\n",
    "# Name of the csv file to save the list\n",
    "file_name = \"design_type_properties.csv\"\n",
    "\n",
    "# Writing the list to a csv file with one column\n",
    "with open(file_name, \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    for item in design_type_properties:\n",
    "        writer.writerow([item])\n",
    "\n",
    "print(\"List saved to\", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64beff88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
